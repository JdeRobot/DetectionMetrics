{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import DetectionMetrics components\n",
    "from detectionmetrics.datasets.coco import CocoDataset\n",
    "from detectionmetrics.models.torch_detection import TorchImageDetectionModel\n",
    "from detectionmetrics.utils import conversion as uc\n",
    "\n",
    "# Set up matplotlib for better visualization\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for data\n",
    "!mkdir -p local/data/models\n",
    "!mkdir -p local/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=9.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset loaded with 118287 samples\n",
      "Number of classes: 80\n"
     ]
    }
   ],
   "source": [
    "# Initialize COCO dataset\n",
    "# Using existing COCO data paths\n",
    "img_dir = \"/Users/sakprave/Downloads/Coco/images/train2017\"\n",
    "ann_file = \"/Users/sakprave/Downloads/Coco/annotations/instances_train2017.json\"\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(img_dir) or not os.path.exists(ann_file):\n",
    "    print(\"COCO data not found. Please check the paths above.\")\n",
    "else:\n",
    "    # Load dataset\n",
    "    dataset = CocoDataset(annotation_file=ann_file, image_dir=img_dir)\n",
    "    print(f\"Dataset loaded with {len(dataset.dataset)} samples\")\n",
    "    print(f\"Number of classes: {len(dataset.ontology)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and configuration saved!\n"
     ]
    }
   ],
   "source": [
    "# Create a pre-trained detection model\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "model.eval()\n",
    "\n",
    "# Save the model\n",
    "model_path = \"local/data/models/maskrcnn_model.pt\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model, model_path)\n",
    "model_cfg = {\n",
    "    \"resize\": {\"height\": 480, \"width\": 640},\n",
    "    \"normalization\": {\n",
    "        \"mean\": [0.485, 0.456, 0.406],\n",
    "        \"std\": [0.229, 0.224, 0.225]\n",
    "    },\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 0,\n",
    "    \"confidence_threshold\": 0.5,\n",
    "    \"nms_threshold\": 0.3\n",
    "}\n",
    "config_path = \"local/data/models/maskrcnn_config.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(model_cfg, f, indent=2)\n",
    "\n",
    "# Save model ontology\n",
    "class_names = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "    \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
    "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\",\n",
    "    \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\",\n",
    "    \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\",\n",
    "    \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "model_ontology = {}\n",
    "for i, name in enumerate(class_names):\n",
    "    model_ontology[str(i + 1)] = {\n",
    "        \"idx\": i + 1,\n",
    "        \"name\": name,\n",
    "        \"rgb\": [0, 0, 0]\n",
    "    }\n",
    "ontology_path = \"local/data/models/coco_model_ontology.json\"\n",
    "with open(ontology_path, \"w\") as f:\n",
    "    json.dump(model_ontology, f, indent=2)\n",
    "\n",
    "# dataset.ontology uses class names as keys\n",
    "ontology_translation = {}\n",
    "for name, data in dataset.ontology.items():\n",
    "    for idx, model_data in model_ontology.items():\n",
    "        if model_data[\"name\"] == name:\n",
    "            ontology_translation[name] = idx\n",
    "            break\n",
    "\n",
    "# Save ontology translation\n",
    "translation_path = \"local/data/models/ontology_translation.json\"\n",
    "with open(translation_path, \"w\") as f:\n",
    "    json.dump(ontology_translation, f, indent=2)\n",
    "\n",
    "print(\"Model and configuration saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not a TorchScript model. Loading as native PyTorch model.\n",
      "Detection model initialized!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "detection_model = TorchImageDetectionModel(\n",
    "    model=model_path,\n",
    "    model_cfg=config_path,\n",
    "    ontology_fname=ontology_path  # This is the model ontology (indices as keys)\n",
    ")\n",
    "\n",
    "# Set ontology and number of classes\n",
    "detection_model.ontology = model_ontology \n",
    "detection_model.n_classes = len(model_ontology)\n",
    "\n",
    "print(\"Detection model initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load a sample image from your dataset\n",
    "dataset.make_fname_global()\n",
    "image_fname = dataset.dataset[\"image\"].iloc[0]\n",
    "image = Image.open(image_fname)\n",
    "\n",
    "detection_model.device = torch.device(\"cpu\")\n",
    "detection_model.model = detection_model.model.to(detection_model.device)\n",
    "# Run inference\n",
    "predictions = detection_model.inference(image)\n",
    "\n",
    "# Get ground truth for comparison\n",
    "annotation_fname = dataset.dataset[\"annotation\"].iloc[0]\n",
    "ground_truth = dataset.read_annotation(annotation_fname)\n",
    "\n",
    "# Simple visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Original image with predictions\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(f\"Predictions ({len(predictions['boxes'])} detections)\")\n",
    "\n",
    "# Draw prediction boxes\n",
    "if len(predictions['boxes']) > 0:\n",
    "    boxes = predictions['boxes'].cpu().numpy()\n",
    "    scores = predictions['scores'].cpu().numpy()\n",
    "    labels = predictions['labels'].cpu().numpy()\n",
    "    \n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Robust class name lookup\n",
    "        label_str = str(label.item()) if hasattr(label, 'item') else str(label)\n",
    "        label_int = int(label.item()) if hasattr(label, 'item') else int(label)\n",
    "        if label_str in detection_model.ontology:\n",
    "            class_name = detection_model.ontology[label_str][\"name\"]\n",
    "        elif label_int in detection_model.ontology:\n",
    "            class_name = detection_model.ontology[label_int][\"name\"]\n",
    "        else:\n",
    "            class_name = f\"Class {label}\"  # fallback\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor='red', facecolor='none', alpha=0.7\n",
    "        )\n",
    "        axes[0].add_patch(rect)\n",
    "        axes[0].text(x1, y1-5, f'{class_name}: {score:.2f}', \n",
    "                    color='red', fontsize=8, weight='bold')\n",
    "\n",
    "# Draw ground truth boxes\n",
    "if len(ground_truth[0]) > 0:\n",
    "    gt_boxes, gt_labels = ground_truth\n",
    "    for box, label in zip(gt_boxes, gt_labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Robust class name lookup for GT\n",
    "        label_str = str(label)\n",
    "        label_int = int(label)\n",
    "        if label_str in dataset.ontology:\n",
    "            class_name = dataset.ontology[label_str][\"name\"]\n",
    "        elif label_int in dataset.ontology:\n",
    "            class_name = dataset.ontology[label_int][\"name\"]\n",
    "        else:\n",
    "            class_name = f\"Class {label}\"\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor='green', facecolor='none', alpha=0.7\n",
    "        )\n",
    "        axes[1].add_patch(rect)\n",
    "        axes[1].text(x1, y1+height+5, f'GT: {class_name}', \n",
    "                    color='green', fontsize=8, weight='bold')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\" Detection Summary:\")\n",
    "print(f\"   Predictions: {len(predictions['boxes'])} objects\")\n",
    "print(f\"   Ground Truth: {len(ground_truth[0])} objects\")\n",
    "print(f\"   Prediction scores: {predictions['scores'].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on a subset of the dataset\n",
    "# For demonstration, we'll use a small subset\n",
    "if 'dataset' in locals():\n",
    "    \n",
    "    # Create a small subset for faster evaluation\n",
    "    small_dataset = dataset.dataset.head(5)  # Use first 5 images for demo\n",
    "    \n",
    "    # Temporarily replace dataset with subset\n",
    "    original_dataset = dataset.dataset\n",
    "    dataset.dataset = small_dataset\n",
    "    \n",
    "    # Reset dataset_dir to the original path since make_fname_global() was called earlier\n",
    "    dataset.dataset_dir = \"/Users/sakprave/Downloads/Coco\"\n",
    "    \n",
    "    # Make sure the output directory exists\n",
    "    predictions_outdir = \"local/outputs/detection_preds\"\n",
    "    os.makedirs(predictions_outdir, exist_ok=True)\n",
    "    \n",
    "    # Path to ontology translation file\n",
    "    ontology_translation_path = \"local/data/models/ontology_translation.json\"\n",
    "    \n",
    "    try:\n",
    "        # Run evaluation with ontology translation\n",
    "        results = detection_model.eval(\n",
    "            dataset=dataset,\n",
    "            split=\"train\",  # Use train split for demo\n",
    "            ontology_translation=ontology_translation_path,  # Add ontology translation\n",
    "            predictions_outdir=predictions_outdir,\n",
    "            results_per_sample=True\n",
    "        )\n",
    "        \n",
    "        print(\" Evaluation completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Evaluation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        # Restore original dataset\n",
    "        dataset.dataset = original_dataset\n",
    "        # Reset dataset_dir back to None (as it was after make_fname_global)\n",
    "        dataset.dataset_dir = None\n",
    "else:\n",
    "    print(\"  Dataset not loaded. Please check the data paths above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
